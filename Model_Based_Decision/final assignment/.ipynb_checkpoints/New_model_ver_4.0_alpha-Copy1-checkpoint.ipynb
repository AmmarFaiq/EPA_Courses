{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install prim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from  ema_workbench.analysis  import parcoords\n",
    "\n",
    "from dike_model_function import *\n",
    "\n",
    "from problem_formulation_ver_4 import *\n",
    "\n",
    "from ema_workbench import Policy, perform_experiments, Scenario, Constraint, ema_logging, MultiprocessingEvaluator\n",
    "from ema_workbench import ema_logging\n",
    "from ema_workbench import MultiprocessingEvaluator\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS, sample_uncertainties\n",
    "from ema_workbench.analysis.scenario_discovery_util import CLASSIFICATION, REGRESSION\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "from analysis import *\n",
    "from ema_workbench.analysis import prim, dimensional_stacking\n",
    "\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume,\n",
    "                                                     EpsilonProgress)\n",
    "import statsmodels.api as sm\n",
    "import prim as prm\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dike Model Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] model initialized\n"
     ]
    }
   ],
   "source": [
    "dike_model = get_model_for_problem_formulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['Expected Annual Costs', 'Total Construction Costs', 'Expected Evacuation Costs', 'Expected Number of Deaths'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dike_model.outcomes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 1000 scenarios * 50 policies * 1 model(s) = 50000 experiments\n"
     ]
    }
   ],
   "source": [
    "n_scenarios = 1000\n",
    "n_policies = 50\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results_randomize = evaluator.perform_experiments(n_scenarios, n_policies)\n",
    "    \n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments_randomize, outcomes_randomize = results_randomize\n",
    "\n",
    "dfexperiment_randomize = pd.DataFrame(data=experiments_randomize)\n",
    "dfoutput_randomize = pd.DataFrame(data=outcomes_randomize)\n",
    "dfcombined_randomize = pd.concat([dfexperiment_randomize, dfoutput_randomize], axis=1)\n",
    "\n",
    "dfexperiment_randomize.to_csv('dfexperiment_randomize.csv', encoding='utf-8', index=False)\n",
    "dfoutput_randomize.to_csv('dfoutput_randomize.csv', encoding='utf-8', index=False)\n",
    "dfcombined_randomize.to_csv('dfcombined_randomize.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read Randomize outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_randomize = pd.read_csv('dfexperiment_randomize.csv')\n",
    "df_output_randomize = pd.read_csv('dfoutput_randomize.csv')\n",
    "df_combined_randomize = pd.read_csv('dfcombined_randomize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import feature_scoring\n",
    "\n",
    "# all input except the levers (uncertainties)\n",
    "x_f = df_experiment_randomize.drop(['scenario_id','policy','model'],axis=1).to_records(index=False)\n",
    "\n",
    "# all output of experiment\n",
    "outcomex = ((df_output_randomize).to_dict('list'))\n",
    "\n",
    "scores = feature_scoring.get_feature_scores_all(x_f, outcomex)\n",
    "plt.figure(figsize = (16,8))\n",
    "sns.heatmap(scores,annot=True,cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Policy and Scenario Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scenario_parameter (Bmax_1 = 30, Bmax_2 = 30,Bmax_3 = 30,Bmax_4 = 30,Bmax_5 = 30,\n",
    "                        pfail_1 = 0, pfail_2 = 0, pfail_3 = 0, pfail_4 = 0, pfail_5 = 0, \n",
    "                        Brate_1 = 0, Brate_2 = 0, Brate_3 = 0, Brate_4 = 0, Brate_5 = 0, \n",
    "                        discount_rate = 0, wave_shape = 0) :\n",
    "    \n",
    "    scenario_0 = {'A.1_Bmax': Bmax_1, 'A.1_pfail': pfail_1, 'A.1_Brate': Brate_1, \n",
    "                    'A.2_Bmax': Bmax_2, 'A.2_pfail': pfail_2, 'A.2_Brate': Brate_2, \n",
    "                    'A.3_Bmax': Bmax_3, 'A.3_pfail': pfail_3, 'A.3_Brate': Brate_3, \n",
    "                    'A.4_Bmax': Bmax_4, 'A.4_pfail': pfail_4, 'A.4_Brate': Brate_4, \n",
    "                    'A.5_Bmax': Bmax_5, 'A.5_pfail': pfail_5, 'A.5_Brate': Brate_5,\n",
    "                    'discount rate': discount_rate,\n",
    "                    'A.0_ID flood wave shape': wave_shape}\n",
    "    return scenario_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levers_parameter (Dike_1 = 0, Dike_2 = 0,Dike_3 = 0,Dike_4 = 0,Dike_5 = 0, \n",
    "                      rfr_0 = 0, rfr_1 = 0, rfr_2 = 0, rfr_3 = 0, rfr_4 = 0,\n",
    "                      EWS = 0) :\n",
    "    \n",
    "    levers_param = {'A.1_DikeIncrease': Dike_1, 'A.2_DikeIncrease': Dike_2, 'A.3_DikeIncrease': Dike_3, \n",
    "                  'A.4_DikeIncrease': Dike_4, 'A.5_DikeIncrease': Dike_5,\n",
    "                  '0_RfR': rfr_0, '1_RfR': rfr_1, '2_RfR': rfr_2, '3_RfR': rfr_3, '4_RfR': rfr_4,\n",
    "                  'EWS_DaysToThreat': EWS}\n",
    "    \n",
    "    return levers_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No Uncertainties\n",
    "scenario_0 = Scenario(\"Scenario_0\", **scenario_parameter())\n",
    "\n",
    "# No Policies\n",
    "policy_0 = Policy(\"No_Policy\", **{l.name:0 for l in dike_model.levers})\n",
    "\n",
    "# Policy with all Maximum mitigation on\n",
    "policy_max = Policy(\"Policy_Max\", **levers_parameter(10,10,10,10,10,1,1,1,1,1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Open Exploration with reference policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 SOBOL open exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 500\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results_sobol_0 = evaluator.perform_experiments(n_scenarios, [policy_0,policy_max], uncertainty_sampling= SOBOL)\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments_sobol_0, outcomes_sobol_0 = results_sobol_0\n",
    "\n",
    "dfexperiment_sobol_0 = pd.DataFrame(data=experiments_sobol_0)\n",
    "dfoutput_sobol_0 = pd.DataFrame(data=outcomes_sobol_0)\n",
    "dfcombined_sobol_0 = pd.concat([dfexperiment_sobol_0, dfoutput_sobol_0], axis=1)\n",
    "\n",
    "dfexperiment_sobol_0.to_csv('dfexperiment_sobol_0.csv', encoding='utf-8', index=False)\n",
    "dfoutput_sobol_0.to_csv('dfoutput_sobol_0.csv', encoding='utf-8', index=False)\n",
    "dfcombined_sobol_0.to_csv('dfcombined_sobol_0.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1 Read SOBOL experiment and predefine definition for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_experiment_sobol_0 = pd.read_csv('dfexperiment_sobol_0.csv')\n",
    "df_output_sobol_0 = pd.read_csv('dfoutput_sobol_0.csv')\n",
    "df_combined_sobol_0 = pd.read_csv('dfcombined_sobol_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_policy_0 = (df_experiment_sobol_0.policy == 'No_Policy')\n",
    "select_policy_max = (df_experiment_sobol_0.policy == 'Policy_Max')\n",
    "\n",
    "no_policy_0 = df_output_sobol_0[select_policy_0]['Expected Number of Deaths'].values\n",
    "max_policy_0 = df_output_sobol_0[select_policy_max]['Expected Number of Deaths'].values\n",
    "\n",
    "sobol_problem = problem = get_SALib_problem(dike_model.uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scores(scores):\n",
    "    scores_filtered = {k:scores[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "    Si_df = pd.DataFrame(scores_filtered, index=problem['names'])\n",
    "\n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    indices = Si_df[['S1','ST']]\n",
    "    err = Si_df[['S1_conf','ST_conf']]\n",
    "\n",
    "    indices.plot.bar(yerr=err.values.T,ax=ax)\n",
    "    fig.set_size_inches(15,12)\n",
    "    fig.subplots_adjust(bottom=0.3)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from math import pi\n",
    "\n",
    "\n",
    "def normalize(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "\n",
    "def plot_circles(ax, locs, names, max_s, stats, smax, smin, fc, ec, lw,\n",
    "                 zorder):\n",
    "    s = np.asarray([stats[name] for name in names])\n",
    "    s = 0.01 + max_s * np.sqrt(normalize(s, smin, smax))\n",
    "\n",
    "    fill = True\n",
    "    for loc, name, si in zip(locs, names, s):\n",
    "        if fc=='w':\n",
    "            fill=False\n",
    "        else:\n",
    "            ec='none'\n",
    "\n",
    "        x = np.cos(loc)\n",
    "        y = np.sin(loc)\n",
    "\n",
    "        circle = plt.Circle((x,y), radius=si, ec=ec, fc=fc, transform=ax.transData._b,\n",
    "                            zorder=zorder, lw=lw, fill=True)\n",
    "        ax.add_artist(circle)\n",
    "\n",
    "\n",
    "def filter(sobol_indices, names, locs, criterion, threshold):\n",
    "    if criterion in ['ST', 'S1', 'S2']:\n",
    "        data = sobol_indices[criterion]\n",
    "        data = np.abs(data)\n",
    "        data = data.flatten() # flatten in case of S2\n",
    "        # TODO:: remove nans\n",
    "\n",
    "        filtered = ([(name, locs[i]) for i, name in enumerate(names) if\n",
    "                     data[i]>threshold])\n",
    "        filtered_names, filtered_locs = zip(*filtered)\n",
    "    elif criterion in ['ST_conf', 'S1_conf', 'S2_conf']:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise ValueError('unknown value for criterion')\n",
    "\n",
    "    return filtered_names, filtered_locs\n",
    "\n",
    "\n",
    "def plot_sobol_indices(sobol_indices, criterion='ST', threshold=0.01):\n",
    "    '''plot sobol indices on a radial plot\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sobol_indices : dict\n",
    "                    the return from SAlib\n",
    "    criterion : {'ST', 'S1', 'S2', 'ST_conf', 'S1_conf', 'S2_conf'}, optional\n",
    "    threshold : float\n",
    "                only visualize variables with criterion larger than cutoff\n",
    "\n",
    "    '''\n",
    "    max_linewidth_s2 = 15\n",
    "    max_s_radius = 0.3\n",
    "\n",
    "    # prepare data\n",
    "    # use the absolute values of all the indices\n",
    "    #sobol_indices = {key:np.abs(stats) for key, stats in sobol_indices.items()}\n",
    "\n",
    "    # dataframe with ST and S1\n",
    "    sobol_stats = {key:sobol_indices[key] for key in ['ST', 'S1']}\n",
    "    sobol_stats = pd.DataFrame(sobol_stats, index=problem['names'])\n",
    "\n",
    "    smax = sobol_stats.max().max()\n",
    "    smin = sobol_stats.min().min()\n",
    "\n",
    "    # dataframe with s2\n",
    "    s2 = pd.DataFrame(sobol_indices['S2'], index=problem['names'],\n",
    "                      columns=problem['names'])\n",
    "    s2[s2<0.0]=0. #Set negative values to 0 (artifact from small sample sizes)\n",
    "    s2max = s2.max().max()\n",
    "    s2min = s2.min().min()\n",
    "\n",
    "    names = problem['names']\n",
    "    n = len(names)\n",
    "    ticklocs = np.linspace(0, 2*pi, n+1)\n",
    "    locs = ticklocs[0:-1]\n",
    "\n",
    "    filtered_names, filtered_locs = filter(sobol_indices, names, locs,\n",
    "                                           criterion, threshold)\n",
    "\n",
    "    # setup figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    ax.grid(False)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "    ax.set_xticks(ticklocs)\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylim(ymax=1.4)\n",
    "    legend(ax)\n",
    "\n",
    "    # plot ST\n",
    "    plot_circles(ax, filtered_locs, filtered_names, max_s_radius,\n",
    "                 sobol_stats['ST'], smax, smin, 'w', 'k', 1, 9)\n",
    "\n",
    "    # plot S1\n",
    "    plot_circles(ax, filtered_locs, filtered_names, max_s_radius,\n",
    "                 sobol_stats['S1'], smax, smin, 'k', 'k', 1, 10)\n",
    "\n",
    "    # plot S2\n",
    "    for name1, name2 in itertools.combinations(zip(filtered_names, filtered_locs), 2):\n",
    "        name1, loc1 = name1\n",
    "        name2, loc2 = name2\n",
    "\n",
    "        weight = s2.ix[name1, name2]\n",
    "        lw = 0.5+max_linewidth_s2*normalize(weight, s2min, s2max)\n",
    "        ax.plot([loc1, loc2], [1,1], c='darkgray', lw=lw, zorder=1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "from matplotlib.legend_handler import HandlerPatch\n",
    "class HandlerCircle(HandlerPatch):\n",
    "    def create_artists(self, legend, orig_handle,\n",
    "                       xdescent, ydescent, width, height, fontsize, trans):\n",
    "        center = 0.5 * width - 0.5 * xdescent, 0.5 * height - 0.5 * ydescent\n",
    "        p = plt.Circle(xy=center, radius=orig_handle.radius)\n",
    "        self.update_prop(p, orig_handle, legend)\n",
    "        p.set_transform(trans)\n",
    "        return [p]\n",
    "\n",
    "def legend(ax):\n",
    "    some_identifiers = [plt.Circle((0,0), radius=5, color='k', fill=False, lw=1),\n",
    "                        plt.Circle((0,0), radius=5, color='k', fill=True),\n",
    "                        plt.Line2D([0,0.5], [0,0.5], lw=8, color='darkgray')]\n",
    "    ax.legend(some_identifiers, ['ST', 'S1', 'S2'],\n",
    "              loc=(1,0.75), borderaxespad=0.1, mode='expand',\n",
    "              handler_map={plt.Circle: HandlerCircle()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 No Policy SOBOL Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a_scores = sobol.analyze(problem, no_policy_0, calc_second_order=True, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(a_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "fig = plot_sobol_indices(a_scores, criterion='ST', threshold=0.005)\n",
    "fig.set_size_inches(7,7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Max Policy SOBOL Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_scores = sobol.analyze(problem, max_policy_0, calc_second_order=True, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_scores(b_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "fig = plot_sobol_indices(b_scores, criterion='ST', threshold=0.005)\n",
    "fig.set_size_inches(7,7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 PRIM open exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 20000\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results_prim_0 = evaluator.perform_experiments(n_scenarios, [policy_0,policy_max])\n",
    "    \n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments_prim_0, outcomes_prim_0 = results_prim_0\n",
    "\n",
    "dfexperiment_prim_0 = pd.DataFrame(data=experiments_prim_0)\n",
    "dfoutput_prim_0 = pd.DataFrame(data=outcomes_prim_0)\n",
    "dfcombined_prim_0 = pd.concat([dfexperiment_prim_0, dfoutput_prim_0], axis=1)\n",
    "\n",
    "dfexperiment_prim_0.to_csv('dfexperiment_prim_0.csv', encoding='utf-8', index=False)\n",
    "dfoutput_prim_0.to_csv('dfoutput_prim_0.csv', encoding='utf-8', index=False)\n",
    "dfcombined_prim_0.to_csv('dfcombined_prim_0.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Read LHS experiment and predefine definition for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_prim_0 = pd.read_csv('dfexperiment_prim_0.csv')\n",
    "df_output_prim_0 = pd.read_csv('dfoutput_prim_0.csv')\n",
    "df_combined_prim_0 = pd.read_csv('dfcombined_prim_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_policy_0 = (df_experiment_prim_0.policy == 'No_Policy')\n",
    "select_policy_max = (df_experiment_prim_0.policy == 'Policy_Max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 No policy PRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select policy to do Prim\n",
    "a_x_prim_0 = df_experiment_prim_0[select_policy_0].drop(['scenario_id','policy','model'],axis=1).to_records(index=False)\n",
    "a_y_prim_0 = (df_output_prim_0[select_policy_0]['Expected Number of Deaths'] > \n",
    "              df_output_prim_0[select_policy_0]['Expected Number of Deaths'].quantile(.95)).astype(int).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prim_alg_0 = prm.Prim(a_x_prim_0, a_y_prim_0, threshold=0.8 ,threshold_type=\">\")\n",
    "box1_0 = prim_alg_0.find_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1_0.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_selection = 56\n",
    "box1_0.select(box_selection)\n",
    "box1_0.show_details()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Max policy PRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_x_prim_0 = df_experiment_prim_0[select_policy_max].drop(['scenario_id','policy','model'],axis=1).to_records(index=False)\n",
    "b_y_prim_0 = (df_output_prim_0[select_policy_max]['Expected Number of Deaths'] > \n",
    "              df_output_prim_0[select_policy_max]['Expected Number of Deaths'].quantile(.95)).astype(int).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prim_alg_max = prm.Prim(b_x_prim_0, b_y_prim_0, threshold=0.8 ,threshold_type=\">\")\n",
    "box1_max = prim_alg_max.find_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1_max.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_selection = 7\n",
    "box1_max.select(box_selection)\n",
    "box1_max.show_details()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 PRIM for comparing zero policy with maximum policy according to objective \"All costs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dike_model.outcomes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_costs_zero = (df_output_prim_0[select_policy_0]['Expected Reactionary Costs']+ \n",
    "                    df_output_prim_0[select_policy_0]['Total Construction Costs'] )\n",
    "total_costs_max = (df_output_prim_0[select_policy_max]['Expected Reactionary Costs'] + \n",
    "                   df_output_prim_0[select_policy_max]['Total Construction Costs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_costs_zero.max() > total_costs_max.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was proven by the code above, that there is exist scenario where \"zero policy\" costs is larger than \"maximum policy\" costs, therefore it is necessary to look for the scenario in which these things happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_x_prim_0 = df_experiment_prim_0[select_policy_0].drop(['scenario_id','policy','model'],axis=1).to_records(index=False)\n",
    "c_y_prim_0 = (total_costs_zero> total_costs_max.max()).astype(int).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prim_alg_c = prm.Prim(c_x_prim_0, c_y_prim_0, threshold=0.8)\n",
    "box1_c = prim_alg_c.find_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1_c.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_selection = 29\n",
    "box1_c.select(box_selection)\n",
    "box1_c.show_details()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After this open exploration, I am planning to change something in the problem formulation (reducing number of uncertainties, lower the boundaries of uncertainties etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for example :\n",
    "# dike_model = get_model_for_problem_formulation(1,Bmax_low=50,Bmax_high=100,pfail_high=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Search over Uncertainties (Worst Case Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(outcome.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change outcomes so direction is undesirable for the uncertainty\n",
    "minimize = ScalarOutcome.MINIMIZE\n",
    "maximize = ScalarOutcome.MAXIMIZE\n",
    "\n",
    "for outcome in dike_model.outcomes:\n",
    "    if outcome.kind == minimize:\n",
    "        outcome.kind = maximize\n",
    "    else:\n",
    "        outcome.kind = minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(outcome.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dike_model.outcomes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj_max = []\n",
    "obj_min = []\n",
    "for name in dike_model.outcomes.keys():\n",
    "    obj_min.append(min(df_output_prim_0[select_policy_0][name].min(),df_output_prim_0[select_policy_max][name].min()))\n",
    "    obj_max.append(max(df_output_prim_0[select_policy_0][name].max(),df_output_prim_0[select_policy_max][name].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Search over worst case in No Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_min_threshold_1 = df_output_prim_0[select_policy_0]['Expected Number of Deaths'].quantile(.975)\n",
    "worst_min_threshold_2 = df_output_prim_0[select_policy_0]['Total Construction Costs'].quantile(.975)\n",
    "worst_min_threshold_3 = df_output_prim_0[select_policy_0]['Expected Reactionary Costs'].quantile(.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraint of the optimization (not use yet)\n",
    "const = [Constraint(\"Death\", outcome_names=\"Expected Number of Deaths\",\n",
    "                         function=lambda x: max(0,worst_min_threshold_1-x)) \n",
    "#         ,Constraint(\"Construction Costs\", outcome_names=\"Total Construction Costs\",\n",
    "#                          function=lambda x: max(0,worst_min_threshold_2-x))\n",
    "        ,Constraint(\"Reactionary Costs\", outcome_names=\"Expected Reactionary Costs\",\n",
    "                         function=lambda x: max(0,worst_min_threshold_3-x))\n",
    "       ]\n",
    "\n",
    "nfe = 10000\n",
    "\n",
    "convergence_metrics = [\n",
    "                       HyperVolume( \n",
    "                                    minimum=obj_min, \n",
    "                                    maximum=obj_max),\n",
    "                       EpsilonProgress()\n",
    "                      ]\n",
    "\n",
    "espilon = [5e4,5e4,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results_uncer_opt_0, convergence_uncer_opt_0 = evaluator.optimize(nfe=nfe, searchover='uncertainties',\n",
    "                                 epsilons=espilon, reference=policy_0, convergence=convergence_metrics,\n",
    "                                             constraints=const\n",
    "                                            )\n",
    "\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(convergence_uncer_opt_0.nfe, convergence_uncer_opt_0.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence_uncer_opt_0.nfe, convergence_uncer_opt_0.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "fig.suptitle('Search Over Worst Case Scenario in \"No Policy\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_uncer_opt_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = results_uncer_opt_0.sort_values(by='Expected Number of Deaths',ascending=False)[(list(dike_model.uncertainties.keys()))].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[0]['A.1_Brate'] = a[0]['A.1_Brate'].value\n",
    "a[0]['A.2_Brate'] = a[0]['A.2_Brate'].value\n",
    "a[0]['A.3_Brate'] = a[0]['A.3_Brate'].value\n",
    "a[0]['A.4_Brate'] = a[0]['A.4_Brate'].value\n",
    "a[0]['A.5_Brate'] = a[0]['A.5_Brate'].value\n",
    "a[0]['discount rate'] = a[0]['discount rate'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_scenario_in_0 = Scenario(\"Worst_in_Zero\", **a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Search over worst case in Max Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_min_threshold_1 = df_output_prim_0[select_policy_0]['Expected Number of Deaths'].quantile(.975)\n",
    "worst_min_threshold_2 = df_output_prim_0[select_policy_0]['Total Construction Costs'].quantile(.975)\n",
    "worst_min_threshold_3 = df_output_prim_0[select_policy_0]['Expected Reactionary Costs'].quantile(.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constraint of the optimization (not use yet)\n",
    "const = [Constraint(\"Death\", outcome_names=\"Expected Number of Deaths\",\n",
    "                         function=lambda x: max(0,worst_min_threshold_1-x)) \n",
    "        ,Constraint(\"Construction Costs\", outcome_names=\"Total Construction Costs\",\n",
    "                         function=lambda x: max(0,worst_min_threshold_2-x))\n",
    "        ,Constraint(\"Reactionary Costs\", outcome_names=\"Expected Reactionary Costs\",\n",
    "                         function=lambda x: max(0,worst_min_threshold_3-x))\n",
    "       ]\n",
    "\n",
    "\n",
    "nfe = 10000\n",
    "\n",
    "convergence_metrics = [\n",
    "                       HyperVolume( \n",
    "                                    minimum=obj_min, \n",
    "                                    maximum=obj_max),\n",
    "                       EpsilonProgress()\n",
    "                      ]\n",
    "\n",
    "espilon = [3e4,3e4,1.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results_uncer_opt_max, convergence_uncer_opt_max = evaluator.optimize(nfe=nfe, searchover='uncertainties',\n",
    "                                 epsilons=espilon, reference=policy_max, convergence=convergence_metrics,\n",
    "                                             constraints=const\n",
    "                                            )\n",
    "\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(convergence_uncer_opt_max.nfe, convergence_uncer_opt_max.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence_uncer_opt_max.nfe, convergence_uncer_opt_max.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "fig.suptitle('Search Over Worst Case Scenario in \"Max Policy\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_uncer_opt_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = results_uncer_opt_max.sort_values(by='Expected Number of Deaths',ascending=False)[(list(dike_model.uncertainties.keys()))].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b[0]['A.1_Brate'] = b[0]['A.1_Brate'].value\n",
    "b[0]['A.2_Brate'] = b[0]['A.2_Brate'].value\n",
    "b[0]['A.3_Brate'] = b[0]['A.3_Brate'].value\n",
    "b[0]['A.4_Brate'] = b[0]['A.4_Brate'].value\n",
    "b[0]['A.5_Brate'] = b[0]['A.5_Brate'].value\n",
    "b[0]['discount rate'] = b[0]['discount rate'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_scenario_in_max = Scenario(\"Worst_in_max\", **b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Search over Levers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(outcome.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change outcomes so direction is desirable for the levers\n",
    "minimize = ScalarOutcome.MINIMIZE\n",
    "maximize = ScalarOutcome.MAXIMIZE\n",
    "\n",
    "for outcome in dike_model.outcomes:\n",
    "    if outcome.kind == minimize:\n",
    "        outcome.kind = maximize\n",
    "    else:\n",
    "        outcome.kind = minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 MORDM with worst scenario in Zero Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_min_threshold_1 = results_uncer_opt_0['Expected Number of Deaths'][0]/2\n",
    "# best_min_threshold_2 = results_uncer_opt_0['All Costs'][0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # constraint of the optimization (not use yet)\n",
    "# const = [Constraint(\"Death\", outcome_names=\"Expected Number of Deaths\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_1)) \n",
    "#         , Constraint(\"Costs\", outcome_names=\"All Costs\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_2)) \n",
    "#        ]\n",
    "\n",
    "nfe = 10000\n",
    "\n",
    "convergence_metrics = [\n",
    "                       HyperVolume( \n",
    "                                    minimum=obj_min, \n",
    "                                    maximum=obj_max),\n",
    "                       EpsilonProgress()\n",
    "                      ]\n",
    "\n",
    "espilon = [1e4,1e4,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_levers_opt_0, convergence_levers_0 = evaluator.optimize(nfe=nfe, searchover='levers', epsilons=espilon,\n",
    "                                                  convergence=convergence_metrics,\n",
    "                                                  reference=worst_scenario_in_0,\n",
    "                                                  #constraints=const\n",
    "                                                  )\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(convergence_levers_0.nfe, convergence_levers_0.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence_levers_0.nfe, convergence_levers_0.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "fig.suptitle('Search Over Levers in Worst case scenario in  \"Zero Policy\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 MORDM with worst Scenario in Max Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_min_threshold_1 = results_uncer_opt_max['Expected Number of Deaths'][0]\n",
    "# best_min_threshold_2 = results_uncer_opt_max['All Costs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # constraint of the optimization (not use yet)\n",
    "# const = [\n",
    "#         Constraint(\"Death\", outcome_names=\"Expected Number of Deaths\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_1)) \n",
    "#          ,Constraint(\"Costs\", outcome_names=\"All Costs\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_2)) \n",
    "#        ]\n",
    "\n",
    "nfe = 10000\n",
    "\n",
    "convergence_metrics = [\n",
    "                       HyperVolume( \n",
    "                                    minimum=obj_min, \n",
    "                                    maximum=obj_max),\n",
    "                       EpsilonProgress()\n",
    "                      ]\n",
    "\n",
    "espilon = [1e4,1e4,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_levers_opt_max, convergence_levers_max = evaluator.optimize(nfe=nfe, searchover='levers', epsilons=espilon,\n",
    "                                                  convergence=convergence_metrics,\n",
    "                                                  reference=worst_scenario_in_max,\n",
    "                                                  #constraints=const\n",
    "                                                  )\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_levers_opt_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(convergence_levers_max.nfe, convergence_levers_max.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence_levers_max.nfe, convergence_levers_max.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "fig.suptitle('Search Over Levers in Worst case scenario in  \"Zero Policy\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Converting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfopt_levers_combined = pd.concat([results_levers_opt_0, results_levers_opt_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfopt_levers_combined.to_csv('dfopt_levers_combined.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_opt_levers_combined = pd.read_csv('dfopt_levers_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_opt_levers_combined.loc[:, [o.name for o in dike_model.outcomes]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, (list(dike_model.outcomes.keys()))] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits,fontsize =10)\n",
    "plt.figure(figsize = (16,8))\n",
    "paraxes.plot(data)\n",
    "\n",
    "# paraxes.invert_axis('Expected Number of Deaths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_min_threshold_1 = df_output_prim_0[select_policy_0]['Expected Number of Deaths'].min()\n",
    "best_min_threshold_2 = results_uncer_opt_0['Total Construction Costs'][0].min()\n",
    "best_min_threshold_3 = df_output_prim_0[select_policy_0]['Expected Reactionary Costs'].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_min_threshold_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constraint of the optimization (not use yet)\n",
    "const = [Constraint(\"Death\", outcome_names=\"Expected Number of Deaths\",\n",
    "                         function=lambda x: max(0,x-best_min_threshold_1)) \n",
    "#         , Constraint(\"Construction Costs\", outcome_names=\"Total Construction Costs\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_2))\n",
    "#          , Constraint(\"Reactionary Costs\", outcome_names=\"Expected Reactionary Costs\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_3)) \n",
    "       ]\n",
    "\n",
    "nfe = 10000\n",
    "\n",
    "convergence_metrics = [\n",
    "                       HyperVolume( \n",
    "                                    minimum=obj_min, \n",
    "                                    maximum=obj_max),\n",
    "                       EpsilonProgress()\n",
    "                      ]\n",
    "\n",
    "espilon = [1e4,1e4,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_levers_opt_0_1, convergence_levers_0_1 = evaluator.optimize(nfe=nfe, searchover='levers', epsilons=espilon,\n",
    "                                                  convergence=convergence_metrics,\n",
    "                                                  reference=worst_scenario_in_0,\n",
    "                                                  constraints=const\n",
    "                                                  )\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_levers_opt_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(convergence_levers_0_1.nfe, convergence_levers_0_1.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence_levers_0_1.nfe, convergence_levers_0_1.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "fig.suptitle('Search Over Levers in Worst case scenario in  \"Zero Policy\" with constaraint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_min_threshold_1 = results_uncer_opt_max['Expected Number of Deaths'][0]/2\n",
    "best_min_threshold_2 = results_uncer_opt_max['Total Construction Costs'][0]/2\n",
    "best_min_threshold_3 = results_uncer_opt_max['Expected Reactionary Costs'][0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constraint of the optimization (not use yet)\n",
    "const = [Constraint(\"Death\", outcome_names=\"Expected Number of Deaths\",\n",
    "                         function=lambda x: max(0,x-best_min_threshold_1)) \n",
    "#         , Constraint(\"Construction Costs\", outcome_names=\"Total Construction Costs\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_2))\n",
    "#          , Constraint(\"Reactionary Costs\", outcome_names=\"Expected Reactionary Costs\",\n",
    "#                          function=lambda x: max(0,x-best_min_threshold_3)) \n",
    "       ]\n",
    "\n",
    "nfe = 10000\n",
    "\n",
    "convergence_metrics = [\n",
    "                       HyperVolume( \n",
    "                                    minimum=obj_min, \n",
    "                                    maximum=obj_max),\n",
    "                       EpsilonProgress()\n",
    "                      ]\n",
    "\n",
    "espilon = [1e4,1e4,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_levers_opt_max_1, convergence_levers_max_1 = evaluator.optimize(nfe=nfe, searchover='levers', epsilons=espilon,\n",
    "                                                  convergence=convergence_metrics,\n",
    "                                                  reference=worst_scenario_in_max,\n",
    "                                                  constraints=const\n",
    "                                                  )\n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_levers_opt_max_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(convergence_levers_max_1.nfe, convergence_levers_max_1.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence_levers_max_1.nfe, convergence_levers_max_1.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "fig.suptitle('Search Over Levers in Worst case scenario in  \"Max Policy\" with constaraint')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfopt_levers_combined_1 = pd.concat([results_levers_opt_0_1, results_levers_opt_max_1])\n",
    "dfopt_levers_combined_1.to_csv('dfopt_levers_combined_1.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_opt_levers_combined_1 = pd.read_csv('dfopt_levers_combined_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_opt_levers_combined_1.loc[:, [o.name for o in dike_model.outcomes]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, (list(dike_model.outcomes.keys()))] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits,fontsize =10)\n",
    "plt.figure(figsize = (16,8))\n",
    "paraxes.plot(data)\n",
    "\n",
    "# paraxes.invert_axis('Expected Number of Deaths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfopt_levers_combined_merge = pd.concat([dfopt_levers_combined, dfopt_levers_combined_1])\n",
    "dfopt_levers_combined_merge.to_csv('dfopt_levers_combined_merge.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_opt_levers_combined_merge = pd.read_csv('dfopt_levers_combined_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_opt_levers_combined_merge.loc[:, [o.name for o in dike_model.outcomes]]\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, (list(dike_model.outcomes.keys()))] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits,fontsize =10)\n",
    "plt.figure(figsize = (16,8))\n",
    "paraxes.plot(data)\n",
    "\n",
    "# paraxes.invert_axis('Expected Number of Deaths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ends here Currently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define scenario and policy found in Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for outcome in dike_model.outcomes:\n",
    "#     print(outcome.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-defined policy based on optimization\n",
    "\n",
    "# Policy from with lowest 'Expected Number of Deaths'\n",
    "# Policy from Worst case scenario\n",
    "policy_1a = Policy(\"Policy_Casualties_A\", **levers_parameter(2,10,9,3,10,1,1,0,1,0,2))\n",
    "policy_1b = Policy(\"Policy_Casualties_B\", **levers_parameter(7,8,8,3,10,0,0,0,1,1,3)) \n",
    "\n",
    "\n",
    "# Policy from with lowest 'All Costs'\n",
    "# Policy from Worst case scenario\n",
    "policy_2a = Policy(\"Policy_Cost_A\", **levers_parameter(7,5,8,4,10,0,0,0,0,0,0))\n",
    "policy_2b = Policy(\"Policy_Cost_B\", **levers_parameter(4,8,7,0,10,0,0,0,0,0,3)) \n",
    "\n",
    "\n",
    "# Policy from with lowest 'Total Construction Costs'\n",
    "# Policy from Worst case scenario\n",
    "policy_3a = Policy(\"Policy_Construction_A\", **levers_parameter(1,0,3,0,0,0,0,0,0,0,3))\n",
    "policy_3b = Policy(\"Policy_Construction_B\", **levers_parameter(4,0,4,3,0,0,0,0,0,0,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform Experiment with defined policy and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [policy_0,policy_1a,policy_1b,policy_1c,policy_1d,policy_2a,policy_2b,policy_2c,policy_2d,policy_3a,policy_3b,policy_3c,policy_3d,policy_4]\n",
    "# [policy_0,policy_max]\n",
    "\n",
    "# number scenarios\n",
    "n_scenarios = 2500\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, [policy_0,\n",
    "                                                          policy_1a,policy_1b,\n",
    "                                                          policy_2a,policy_2b,\n",
    "                                                          policy_3a,policy_3b,\n",
    "                                                          policy_lever_deaths,\n",
    "                                                          policy_lever_cost,\n",
    "                                                          policy_dikes,policy_rfr,\n",
    "                                                          policy_max])\n",
    "    \n",
    "end = time.time()\n",
    "print('Processing time :',(end - start)/60, 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiments, outcomes = results\n",
    "# dfexperiment = pd.DataFrame(data=experiments)\n",
    "# dfoutput = pd.DataFrame(data=outcomes)\n",
    "\n",
    "# dfoutput['policy'] = dfexperiment['policy']\n",
    "\n",
    "# sns.pairplot(dfoutput, hue='policy',  vars=dfoutput.columns.drop('policy'), )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert result into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "dfexperiment = pd.DataFrame(data=experiments)\n",
    "dfoutput = pd.DataFrame(data=outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([dfexperiment, dfoutput], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfexperiment.to_csv('dfexperiment.csv', encoding='utf-8', index=False)\n",
    "dfoutput.to_csv('dfoutput.csv', encoding='utf-8', index=False)\n",
    "combined.to_csv('combined.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_experiment = pd.read_csv('dfexperiment.csv')\n",
    "df_output = pd.read_csv('dfoutput.csv')\n",
    "_combined = pd.read_csv('combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df_output.columns[(df_output.columns.str.contains('A.2'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output['policy'] = df_experiment['policy']\n",
    "\n",
    "# for i, policy in enumerate(set(policies)):\n",
    "#     policies[policies==policy] = str(i)\n",
    "\n",
    "# Filter data policy\n",
    "filter_data = df_output\n",
    "filter_data  = df_output.drop(df_output[(df_output.policy.str.contains('No_Policy')) |\n",
    "                                        #(df_output.policy.str.contains('Casualties')) |\n",
    "                                        (df_output.policy.str.contains('Casualties')) |\n",
    "                                        #(df_output.policy.str.contains('Casualties_b')) |\n",
    "                                        (df_output.policy.str.contains('Cost')) |\n",
    "                                        #(df_output.policy.str.contains('Cost_b')) |\n",
    "                                        #(df_output.policy.str.contains('Cost_c')) |\n",
    "                                        (df_output.policy.str.contains('Damage')) | \n",
    "                                        (df_output.policy.str.contains('Construction')) #| \n",
    "                                        #(df_output.policy.str.contains('Cost')) #| \n",
    "                                        #(df_output.policy.str.contains('Max'))\n",
    "                                        ].index)\n",
    "# Filter data objective\n",
    "filter_data = filter_data.drop(list(df_output.columns[(df_output.columns.str.contains('A.2'))])+\n",
    "                                list(df_output.columns[(df_output.columns.str.contains('A.4'))])+\n",
    "                               list(df_output.columns[(df_output.columns.str.contains('A.5'))])+\n",
    "                                #df_output.columns[(df_output.columns.str.contains('A.4'))].values,\n",
    "                                #'Expected Evacuation Costs',\n",
    "                                ['Expected Investment Costs']\n",
    "                                #'All Costs',\n",
    "                                #'Expected Annual Damage',\n",
    "                                #'Expected Number of Deaths',\n",
    "                                #'Total Construction Costs',\n",
    "                               ,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ploting the results\n",
    "sns.pairplot(filter_data, hue='policy',  vars=filter_data.columns.drop('policy'), )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df_output.drop('policy',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)\n",
    "\n",
    "regret = {}\n",
    "max_regret = {}\n",
    "for outcome in dike_model.outcomes:\n",
    "    policy_column = df_experiment['policy']=\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: df_output[outcome.name], \n",
    "                         \"policy\":df_experiment['policy'],\n",
    "                         \"scenario_id\":df_experiment['scenario_id']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario_id', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1)[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    regret[outcome.name] = regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_regret  = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data  =  max_regret\n",
    "\n",
    "# # makes it easier to identify the policy associated with each line\n",
    "# # in the parcoords plot\n",
    "# data['policy id'] = data.index.astype(\"float64\")\n",
    "\n",
    "# limits = parcoords.get_limits(data)\n",
    "# limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "# paraxes = parcoords.ParallelAxes(limits)\n",
    "# paraxes.plot(data)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# data = df_lever_opt.loc[:5, [o.name for o in dike_model.outcomes]]\n",
    "# limits = parcoords.get_limits(data)\n",
    "# limits.loc[0, (list(dike_model.outcomes.keys()))] = 0\n",
    "\n",
    "# paraxes = parcoords.ParallelAxes(limits,fontsize =10)\n",
    "# plt.figure(figsize = (16,8))\n",
    "# paraxes.plot(data)\n",
    "\n",
    "# # paraxes.invert_axis('Expected Number of Deaths')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
