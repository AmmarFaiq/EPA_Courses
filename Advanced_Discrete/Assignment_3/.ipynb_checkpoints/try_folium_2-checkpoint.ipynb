{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install folium\n",
    "#!pip install ipywidgets\n",
    "import folium\n",
    "from folium import plugins\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# path of bridge data for reading csv file (_roads2)\n",
    "road_path     = 'D:\\Jupyter_File\\Advanced_Discrete_Cleaning\\WBSIM_Lab2\\infrastructure\\_roads3.csv'\n",
    "\n",
    "# path of bridge data for reading Excel file (BMMS_overview)\n",
    "bridge_path     = 'D:\\Jupyter_File\\Advanced_Discrete_Cleaning\\WBSIM_Lab2\\infrastructure\\BMMS_overview.xlsx'\n",
    "\n",
    "# Set filepath (fix path relative to yours)\n",
    "fp = 'D:/Jupyter_File/Advanced_Discrete_Cleaning/Assignment_3/bangladesh_floods_adm4'\n",
    "\n",
    "# define variables\n",
    "path  = 'D:\\Jupyter_File\\Advanced_Discrete_Cleaning\\RMMS' # path to RMMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(road_path,bridge_path,fp,path):    \n",
    "    \n",
    "    df_orig  = pd.read_csv(road_path,index_col=None, header=0)\n",
    "    \n",
    "    bdf_orig = pd.read_excel(bridge_path, index_col=None, header=0)\n",
    "    \n",
    "    flood_shhp_data = gpd.read_file(fp)\n",
    "    \n",
    "    flood_geoPath = flood_shhp_data.geometry.to_json\n",
    "    \n",
    "    rname0 = 'N1'\n",
    "    textPath = path + '\\\\' + rname0 + '.widths.processed.txt'\n",
    "    width_data0      = pd.read_table(textPath)\n",
    "\n",
    "    # reading raw html\n",
    "    htmlPath = path + '\\\\' + rname0 + \".traffic.htm\"\n",
    "    rawHtml0  = pd.read_html(htmlPath)[4]\n",
    "\n",
    "    rawHtml0.loc[2,0] = 'LinkNo'\n",
    "    rawHtml0.loc[2,1] = 'LinkName'\n",
    "    rawHtml0.loc[2,4] = 'ChainageS'\n",
    "    rawHtml0.loc[2,7] = 'ChainageE'\n",
    "\n",
    "    # select only table information\n",
    "    html_data0         = rawHtml0.loc[3:len(rawHtml0),:] \n",
    "\n",
    "    # change column name\n",
    "    html_data0.columns = rawHtml0.loc[2,:]\n",
    "    html_data0 = html_data0.reset_index(drop=True)\n",
    "    html_data0['width'] = np.nan\n",
    "    html_data0['nrLanes'] = np.nan\n",
    "    html_data0 = html_data0.rename(index=str, columns={\"(Km)\": \"Distance\", \"(AADT)\": \"AADT\"})\n",
    "    html_data0 = html_data0.drop('Total AADT', axis=1)\n",
    "    html_data0.columns.values[0] = 'road'\n",
    "    html_data0.columns.values[2] = 'LRPStart'\n",
    "    html_data0.columns.values[3] = 'OffsetStart'\n",
    "    html_data0.columns.values[5] = 'LRPEnd'\n",
    "    html_data0.columns.values[6] = 'OffsetEnd'\n",
    "       \n",
    "    notfound = []\n",
    "    \n",
    "    # import txt width lanes files\n",
    "    for i in range (1,len(bdf_orig.road.value_counts().index)):\n",
    "        rname = bdf_orig.road.value_counts().index[i]\n",
    "        try:\n",
    "            textPath = path + '\\\\' + rname + '.widths.processed.txt'\n",
    "            width_data      = pd.read_table(textPath)\n",
    "\n",
    "            # reading raw html\n",
    "            htmlPath = path + '\\\\' + rname + \".traffic.htm\"\n",
    "            rawHtml  = pd.read_html(htmlPath)[4]\n",
    "\n",
    "            rawHtml.loc[2,0] = 'LinkNo'\n",
    "            rawHtml.loc[2,1] = 'LinkName'\n",
    "            rawHtml.loc[2,4] = 'ChainageS'\n",
    "            rawHtml.loc[2,7] = 'ChainageE'\n",
    "\n",
    "            # select only table information\n",
    "            html_data         = rawHtml.loc[3:len(rawHtml),:] \n",
    "\n",
    "            # change column name\n",
    "            html_data.columns = rawHtml.loc[2,:]\n",
    "            html_data = html_data.reset_index(drop=True)\n",
    "            html_data['width'] = np.nan\n",
    "            html_data['nrLanes'] = np.nan\n",
    "            html_data = html_data.rename(index=str, columns={\"(Km)\": \"Distance\", \"(AADT)\": \"AADT\"})\n",
    "            html_data = html_data.drop('Total AADT', axis=1)\n",
    "            html_data.columns.values[0] = 'road'\n",
    "            html_data.columns.values[2] = 'LRPStart'\n",
    "            html_data.columns.values[3] = 'OffsetStart'\n",
    "            html_data.columns.values[5] = 'LRPEnd'\n",
    "            html_data.columns.values[6] = 'OffsetEnd'\n",
    "\n",
    "            width_data0  = pd.concat([width_data0, width_data])\n",
    "            html_data0  = pd.concat([html_data0, html_data])\n",
    "            \n",
    "        except:\n",
    "            notfound.append(bdf_orig.road.value_counts().index[i])\n",
    "    \n",
    "    return df_orig,bdf_orig,flood_shhp_data,flood_geoPath,width_data0,html_data0,notfound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_data(rname,df,bdf,width_data_final,html_data_final):\n",
    "    # Create dataframe for selected roads for BMMS and roads data\n",
    "    df_selected  = df[(df['road'] == rname)].sort_values(by = 'chainage')\n",
    "    bdf_selected = bdf[(bdf['road'] == rname)].sort_values(by = 'chainage')\n",
    "\n",
    "    df_selected['width'] = np.nan\n",
    "    df_selected['Length'] = np.nan\n",
    "    df_selected['Quality'] = np.nan\n",
    "    df_selected['LinkName'] = np.nan\n",
    "    df_selected['constructionYear'] = np.nan\n",
    "\n",
    "    # mark which data is from which source\n",
    "    df_selected['Data_source'] = 'road3'\n",
    "    bdf_selected['Data_source'] = 'BMMS'\n",
    "\n",
    "    # drop unnecessary column that is not needed in the construction of excel files\n",
    "    df_selected = df_selected.drop(['gap'], axis=1)\n",
    "    bdf_selected = bdf_selected.drop(['km', 'structureNr', 'spans', \n",
    "                                      'zone','circle','division',\n",
    "                                      'sub-division', 'EstimatedLoc'], axis=1)\n",
    "\n",
    "    # Script to drop \"Bridges\" included in the roads data\n",
    "    df_selected = df_selected.drop(df_selected[df_selected['type'] == 'Bridge'].index)\n",
    "\n",
    "    # rename some columns names\n",
    "    bdf_selected = bdf_selected.rename(index=str, columns={'LRPName': 'lrp' ,'condition':'Quality',\n",
    "                                                           'length':'Length', 'roadName':'LinkName'})\n",
    "\n",
    "    # Combined roads and bridges data\n",
    "    df1_combined = pd.concat([df_selected, bdf_selected]).sort_values(by = 'chainage')\n",
    "\n",
    "    # drop duplicates\n",
    "    df1_combined = df1_combined.drop_duplicates(subset = ['lrp'], keep = 'first', inplace=False)\n",
    "    df1_combined = df1_combined.sort_values(by = 'chainage').reset_index(drop = True)\n",
    "    \n",
    "    # Filling the quality of the road based on the quality of the bridge (FIRST TRY, PLEASE REMOVE IT AFTERWARDS)\n",
    "    df1_combined['Quality'] = df1_combined.Quality.fillna(method='bfill')\n",
    "    \n",
    "    # selected dataframe for width data\n",
    "    width_data_final_selected  = width_data_final[(width_data_final['roadNo'] == rname)].sort_values(by = 'startChainage')\n",
    "\n",
    "    # selected dataframe for html data\n",
    "    # deleting character name after \"-\" character to the data\n",
    "    html_data_final['road'] = html_data_final['road'].apply(lambda x: x[:x.rfind(\"-\")])\n",
    "    html_data_final_selected  = html_data_final[(html_data_final['road'] == rname)].sort_values(by = 'ChainageS')\n",
    "    \n",
    "    return df1_combined,width_data_final_selected,html_data_final_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(df1_combined):\n",
    "# Load map centred on average coordinates\n",
    "\n",
    "    my_map = folium.Map(location=[df1_combined.lat.mean(), df1_combined.lon.mean()], zoom_start=8)\n",
    "\n",
    "    for i in range(len(df1_combined)-1):\n",
    "        points = []\n",
    "        if (df1_combined['Quality'][i]=='A'):\n",
    "            points.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "            points.append(tuple([df1_combined.lat[i+1], df1_combined.lon[i+1]]))\n",
    "            folium.PolyLine(points, color=\"green\", weight=2.5, opacity=1).add_to(my_map)\n",
    "        elif (df1_combined['Quality'][i]=='B'):\n",
    "            points.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "            points.append(tuple([df1_combined.lat[i+1], df1_combined.lon[i+1]]))\n",
    "            folium.PolyLine(points, color=\"yellow\", weight=2.5, opacity=1).add_to(my_map)\n",
    "        elif (df1_combined['Quality'][i]=='C'):\n",
    "            points.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "            points.append(tuple([df1_combined.lat[i+1], df1_combined.lon[i+1]]))\n",
    "            folium.PolyLine(points, color=\"orange\", weight=2.5, opacity=1).add_to(my_map)\n",
    "        elif (df1_combined['Quality'][i]=='D'):\n",
    "            points.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "            points.append(tuple([df1_combined.lat[i+1], df1_combined.lon[i+1]]))\n",
    "            folium.PolyLine(points, color=\"red\", weight=2.5, opacity=1).add_to(my_map)\n",
    "\n",
    "\n",
    "    for i in range(len(df1_combined)):\n",
    "        if (df1_combined['Data_source'][i] == 'BMMS'):\n",
    "            points_bridges = []\n",
    "            if(df1_combined['Quality'][i]=='A'):\n",
    "                points_bridges.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "                testa = folium.Html('<b>A bridges!</b>', script=True)\n",
    "                popupa = folium.Popup(testa, max_width=2650)\n",
    "                folium.RegularPolygonMarker(points_bridges[0],popup=popupa,fill_color='#61ff00',\n",
    "                                            number_of_sides=4,radius=8).add_to(my_map)\n",
    "\n",
    "            elif(df1_combined['Quality'][i]=='B'):\n",
    "                points_bridges.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "                testb = folium.Html('<b>B bridges!</b>', script=True)\n",
    "                popupb = folium.Popup(testb, max_width=2650)\n",
    "                folium.RegularPolygonMarker(points_bridges[0],popup=popupb,fill_color='#fffa00',\n",
    "                                            number_of_sides=4,radius=8).add_to(my_map)\n",
    "\n",
    "            elif(df1_combined['Quality'][i]=='C'):\n",
    "                points_bridges.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "                testc = folium.Html('<b>C bridges!</b>', script=True)\n",
    "                popupc = folium.Popup(testc, max_width=2650)\n",
    "                folium.RegularPolygonMarker(points_bridges[0],popup=popupc,fill_color='#ffa100',\n",
    "                                            number_of_sides=4,radius=8).add_to(my_map)\n",
    "\n",
    "            elif(df1_combined['Quality'][i]=='D'):\n",
    "                points_bridges.append(tuple([df1_combined.lat[i], df1_combined.lon[i]]))\n",
    "                testd = folium.Html('<b>D bridges!</b>', script=True)\n",
    "                popupd = folium.Popup(testd, max_width=2650)\n",
    "                folium.RegularPolygonMarker(points_bridges[0],popup=popupd,fill_color='#ff0000',\n",
    "                                            number_of_sides=4,radius=8).add_to(my_map)\n",
    "\n",
    "    return my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname = 'N2' # name of the road to load\n",
    "df_orig,bdf_orig,flood_shhp_data,flood_geoPath,width_data0,html_data0,notfound = import_data(road_path,bridge_path,fp,path)\n",
    "df1_combined,width_data_final_selected,html_data_final_selected = selected_data(rname,df_orig,bdf_orig,width_data0,html_data0)\n",
    "plot_map(df1_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
