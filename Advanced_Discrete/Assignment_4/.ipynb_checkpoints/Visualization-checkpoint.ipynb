{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.map import *\n",
    "from folium import features\n",
    "\n",
    "import os\n",
    "os.chdir(os.getcwd())\n",
    "import json\n",
    "import webbrowser\n",
    "import math\n",
    "from selenium import webdriver\n",
    "import imageio\n",
    "\n",
    "import timeit\n",
    "import pymysql\n",
    "import pymysql.cursors\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from ipywidgets import *\n",
    "\n",
    "# path of road data for reading csv file (_roads3)\n",
    "road_path     = '_roads3.csv'\n",
    "\n",
    "# path of bridge data for reading Excel file (BMMS_overview)\n",
    "bridge_path     = 'BMMS_overview.xlsx'\n",
    "\n",
    "# folder path of html traffic data and width.processed txt files \n",
    "path  = 'RMMS' # path to RMMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path,road_path,bridge_path,rname0='N1'):    \n",
    "    # read _roads3.csv datafile  \n",
    "    df_orig  = pd.read_csv(road_path,index_col=None, header=0)\n",
    "\n",
    "    # read BMMS_overview.xlsx datafile \n",
    "    bdf_orig = pd.read_excel(bridge_path, index_col=None, header=0)\n",
    "\n",
    "    # Create blank column for roads dataframe to match with the bridge dataframe format \n",
    "    df_orig['width'] = np.nan\n",
    "    df_orig['Length'] = np.nan\n",
    "    df_orig['Quality'] = np.nan\n",
    "    df_orig['LinkName'] = np.nan\n",
    "    df_orig['constructionYear'] = np.nan\n",
    "\n",
    "    # Mark which data is from which source (BMMS_overview or _roads3)\n",
    "    df_orig['Data_source'] = 'road3' #_roads3.csv source\n",
    "    bdf_orig['Data_source'] = 'BMMS'  #BMMS_overview.xlsx source\n",
    "\n",
    "    # drop unnecessary column that is not needed in the construction of excel files\n",
    "    df_orig = df_orig.drop(['gap'], axis=1)\n",
    "    bdf_orig = bdf_orig.drop(['km', 'structureNr', 'spans', \n",
    "                                      'zone','circle','division',\n",
    "                                      'sub-division', 'EstimatedLoc'], axis=1)\n",
    "\n",
    "    # Script to drop \"Bridges\" included in the roads data\n",
    "    df_orig = df_orig.drop(df_orig[df_orig['type'] == 'Bridge'].index)\n",
    "\n",
    "    # Rename some columns names to match with the roads dataframe\n",
    "    bdf_orig = bdf_orig.rename(index=str, columns={'LRPName': 'lrp' ,'condition':'Quality',\n",
    "                                                           'length':'Length', 'roadName':'LinkName'})\n",
    "\n",
    "    # Combined roads and bridges data\n",
    "    df1_combined = pd.concat([df_orig, bdf_orig])\n",
    "\n",
    "    # Choose only road name\n",
    "    df1_combined = df1_combined[(df1_combined['road'] == rname0)]\n",
    "\n",
    "    # Reading raw intial text files for width\n",
    "    textPath = path + '\\\\' + rname0 + '.widths.processed.txt' # define the path\n",
    "    width_data0      = pd.read_table(textPath) #reading the txt files based on the path\n",
    "\n",
    "    # Marking the datasource of width.processed.txt\n",
    "    width_data0['Data_source'] = 'widths'\n",
    "\n",
    "    # Reading raw initial html (N1)\n",
    "    htmlPath = path + '\\\\' + rname0 + \".traffic.htm\"\n",
    "\n",
    "    # Read the raw html files and choose only table data from the html files which in the fourth structure\n",
    "    rawHtml0  = pd.read_html(htmlPath)[4]\n",
    "\n",
    "    # Change some variables columns names in html file, number is used, since there are duplicates column name\n",
    "    rawHtml0.loc[2,0] = 'LinkNo'\n",
    "    rawHtml0.loc[2,1] = 'LinkName'\n",
    "    rawHtml0.loc[2,4] = 'ChainageS'\n",
    "    # later on the when combining the whole dataframe, we only select end of chainage as the representative of the data \n",
    "    # since there are start and end chainage that have the same data\n",
    "    rawHtml0.loc[2,7] = 'chainage'\n",
    "\n",
    "    # select only table information\n",
    "    html_data0         = rawHtml0.loc[3:len(rawHtml0),:] \n",
    "\n",
    "    # change column name and create some blank columns to match with other dataframe\n",
    "    html_data0.columns = rawHtml0.loc[2,:]\n",
    "    html_data0 = html_data0.reset_index(drop=True)\n",
    "    html_data0['width'] = np.nan\n",
    "    html_data0['Data_source'] = 'html'\n",
    "    html_data0 = html_data0.rename(index=str, columns={\"(Km)\": \"Distance\", \"(AADT)\": \"AADT\"})\n",
    "    html_data0 = html_data0.drop('Total AADT', axis=1)\n",
    "    html_data0.columns.values[0] = 'road'\n",
    "    html_data0.columns.values[2] = 'LRPStart'\n",
    "    html_data0.columns.values[3] = 'OffsetStart'\n",
    "    html_data0.columns.values[5] = 'lrp'\n",
    "    html_data0.columns.values[6] = 'OffsetEnd'\n",
    "\n",
    "    # function to sum left and right lanes traffic for initial \n",
    "    html_data0 = html_data0.apply(pd.to_numeric,errors='ignore').sort_values(by='chainage') # convert data to numeric from strings\n",
    "    for i in range(len(html_data0)-1):\n",
    "        if (html_data0.iloc[i,7]) == (html_data0.iloc[i+1,7]):\n",
    "            for j in range(9,len(html_data0.columns)-1):\n",
    "                html_data0.iloc[i,j] = (html_data0.iloc[i,j]) + (html_data0.iloc[i+1,j])\n",
    "                \n",
    "    # drop the left and right lanes in the html data\n",
    "    html_data0 = html_data0.drop_duplicates(subset='chainage',keep='first').reset_index(drop=True)\n",
    "\n",
    "    # deleting character name after \"-\" character to the data\n",
    "    html_data0['road'] = html_data0['road'].apply(lambda x: x[:x.rfind(\"-\")])\n",
    "\n",
    "    # Rename some columns for combined width text files while deleting unimportant columns\n",
    "\n",
    "    # oredering and selecting important column for combined html files\n",
    "    html_data0 = html_data0[['Data_source','road','chainage','lrp','Heavy Truck', 'Medium Truck',\n",
    "                             'Small Truck', 'Large Bus', 'Medium Bus', 'Micro Bus', 'Utility', 'Car',\n",
    "                             'Auto Rickshaw', 'Motor Cycle', 'Bi-Cycle', 'Cycle Rickshaw', 'Cart',\n",
    "                             'Motorized', 'Non Motorized', 'AADT', 'width']]\n",
    "\n",
    "    df1_universal = pd.concat([df1_combined, html_data0])\n",
    "    df1_universal = df1_universal.apply(pd.to_numeric,errors='ignore')\n",
    "    \n",
    "    df1_universal = df1_universal.sort_values(by = 'chainage').reset_index(drop = True)\n",
    "    df1_universal = df1_universal.loc[0:744]\n",
    "    \n",
    "    # fill all NaN values with the next nearest datasets avaliable \n",
    "    df1_universal = df1_universal.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # drop duplicates based on lrp\n",
    "    #df1_universal = df1_universal.drop_duplicates(subset = ['lrp'], keep = 'first', inplace=False).reset_index(drop = True)\n",
    "    \n",
    "    return df1_universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "df_all_data = load_files(path,road_path,bridge_path,rname0='N1')\n",
    "df_all_info = df_all_data[['lrp','lat','lon','Data_source','chainage','Quality']]\n",
    "df_all_info = df_all_info.rename(index=str, columns={\"lrp\": \"SegmentName\"})\n",
    "\n",
    "df_all_info_bridge = df_all_info[df_all_info['Data_source']=='BMMS'].reset_index(drop=True).drop(['Data_source'],axis=1)\n",
    "df_all_info_bridge = df_all_info_bridge.rename(index=str, columns={\"SegmentName\": \"BridgeName\"})\n",
    "\n",
    "df_all_info = df_all_info.drop(['Data_source'],axis=1)\n",
    "\n",
    "stop_time = timeit.default_timer()\n",
    "\n",
    "print('Total time for data preparation calculation: ', (stop_time-start_time), 'Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to fully map the simulation with all the bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_complete(df_sql_bridges_combined,df_sql_roads_combined):\n",
    "\n",
    "    # Load map centered of bangladesh\n",
    "    my_map = folium.Map(location=[df_sql_roads_combined.lat.median(), df_sql_roads_combined.lon.median()], zoom_start=8.8)\n",
    "    # Make a legend for vulnerability score color\n",
    "    linear_roads = folium.LinearColormap(['green','yellow','red'], vmin=df_sql_roads_combined['NumberOfVehicles'].min(), vmax=df_sql_roads_combined['NumberOfVehicles'].max(), caption = 'Traffic Score per Hour')\n",
    "    linear_bridges = folium.LinearColormap(['blue','purple','red'], vmin=1, vmax=5, caption = 'Vulnerability Score')\n",
    "    my_map.add_child(linear_roads)\n",
    "    my_map.add_child(linear_bridges)\n",
    "    \n",
    "    feature_group_bridges_a = folium.map.FeatureGroup(name='Bridges A')\n",
    "    feature_group_bridges_b = folium.map.FeatureGroup(name='Bridges B')\n",
    "    feature_group_bridges_c = folium.map.FeatureGroup(name='Bridges C')\n",
    "    feature_group_bridges_d = folium.map.FeatureGroup(name='Bridges D')\n",
    "    feature_group_bridges_broken = folium.map.FeatureGroup(name='Bridges Broke')\n",
    "    \n",
    "    # Create a road line one by one by its lattitude and longitude\n",
    "    for i in range(len(df_sql_roads_combined)-1):\n",
    "        # blanks list of coordinates\n",
    "        points = []\n",
    "        # insert two coordinates to connect the line of road segments\n",
    "        points.append(tuple([df_sql_roads_combined.lat[i], df_sql_roads_combined.lon[i]]))\n",
    "        points.append(tuple([df_sql_roads_combined.lat[i+1], df_sql_roads_combined.lon[i+1]]))\n",
    "            \n",
    "        # insert the html popup information into folium popup\n",
    "        testa = folium.Html(\"\"\"<h3>\"\"\" + 'N1' +\"\"\"_\"\"\"+  df_sql_roads_combined.SegmentName[i] +' to ' + df_sql_roads_combined.SegmentName[i+1] +' Road'+\"\"\"\"</h3>\"\"\" , script=True)\n",
    "        popupa = folium.Popup(testa, max_width=2650)\n",
    "    \n",
    "        # create the line of the roads\n",
    "        folium.PolyLine(points, color=linear_roads.to_step(15)(df_sql_roads_combined.loc[i,'NumberOfVehicles']), \n",
    "                        weight=10,popup=popupa, opacity=0.85).add_to(my_map)\n",
    "\n",
    "    # the same as roads, but this is for bridges\n",
    "    for i in range(len(df_sql_bridges_combined)):\n",
    "\n",
    "        # blank bridges coordinates list\n",
    "        points_bridges = []\n",
    "        #insert the bridge coordinates\n",
    "        points_bridges.append(tuple([df_sql_bridges_combined.lat[i], df_sql_bridges_combined.lon[i]]))\n",
    "        \n",
    "        # insert the html popup information into folium popup        \n",
    "        testb = folium.Html(\"\"\"<h3>\"\"\" + 'N1' +\"\"\"_\"\"\"+  df_sql_bridges_combined.BridgeName[i] +' Bridge' +\"\"\"</h3>\"\"\" , script=True)\n",
    "        popupb = folium.Popup(testb, max_width=2650)\n",
    "        \n",
    "        # Layering the bridge based on its quality\n",
    "        if (df_sql_bridges_combined['Broken'][i] == 1):\n",
    "            feature_group_bridges_broken.add_child(folium.RegularPolygonMarker(points_bridges[0], popup=popupb,\n",
    "                                                    fill_color=linear_bridges.to_step(5)(5),\n",
    "                                                    number_of_sides=4, radius=7))\n",
    "        else :    \n",
    "            if (df_sql_bridges_combined['Quality'][i] == 'B'):\n",
    "                feature_group_bridges_b.add_child(folium.RegularPolygonMarker(points_bridges[0], popup=popupb,\n",
    "                                                fill_color=linear_bridges.to_step(5)(2),\n",
    "                                                number_of_sides=4, radius=7))\n",
    "            if (df_sql_bridges_combined['Quality'][i] == 'C'):\n",
    "                feature_group_bridges_c.add_child(folium.RegularPolygonMarker(points_bridges[0], popup=popupb,\n",
    "                                                fill_color=linear_bridges.to_step(5)(3),\n",
    "                                                number_of_sides=4,radius=7))\n",
    "            if (df_sql_bridges_combined['Quality'][i] == 'D'):\n",
    "                feature_group_bridges_d.add_child(folium.RegularPolygonMarker(points_bridges[0], popup=popupb,\n",
    "                                                fill_color=linear_bridges.to_step(5)(4),\n",
    "                                                number_of_sides=4,radius=7))\n",
    "            else :\n",
    "                feature_group_bridges_a.add_child(folium.RegularPolygonMarker(points_bridges[0], popup=popupb,\n",
    "                                                fill_color=linear_bridges.to_step(5)(1),\n",
    "                                                number_of_sides=4,radius=7))\n",
    "\n",
    "    # Add the layer of bridges into the map            \n",
    "    \n",
    "    my_map.add_child(feature_group_bridges_a)\n",
    "    my_map.add_child(feature_group_bridges_b)\n",
    "    my_map.add_child(feature_group_bridges_c)\n",
    "    my_map.add_child(feature_group_bridges_d)\n",
    "    my_map.add_child(feature_group_bridges_broken)\n",
    "\n",
    "    # add the check box control button into the map\n",
    "    my_map.add_child(folium.map.LayerControl())\n",
    "\n",
    "    return my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to map the simulation with only the broken bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_mini(df_sql_bridges_combined,df_sql_roads_combined):\n",
    "\n",
    "    # Load map centered of bangladesh\n",
    "    my_map = folium.Map(location=[df_sql_roads_combined.lat.median(), df_sql_roads_combined.lon.median()], zoom_start=8.8)\n",
    "    # Make a legend for vulnerability score color\n",
    "    linear_roads = folium.LinearColormap(['green','yellow','red'], vmin=df_sql_roads_combined['NumberOfVehicles'].min(), vmax=df_sql_roads_combined['NumberOfVehicles'].max(), caption = 'Traffic Score per Hour')\n",
    "    linear_bridges = folium.LinearColormap(['blue','purple','red'], vmin=1, vmax=5, caption = 'Vulnerability Score')\n",
    "    my_map.add_child(linear_roads)\n",
    "    my_map.add_child(linear_bridges)\n",
    "    \n",
    "    feature_group_bridges_broken = folium.map.FeatureGroup(name='Bridges Broke')\n",
    "    \n",
    "    # Create a road line one by one by its lattitude and longitude\n",
    "    for i in range(len(df_sql_roads_combined)-1):\n",
    "        # blanks list of coordinates\n",
    "        points = []\n",
    "        # insert two coordinates to connect the line of road segments\n",
    "        points.append(tuple([df_sql_roads_combined.lat[i], df_sql_roads_combined.lon[i]]))\n",
    "        points.append(tuple([df_sql_roads_combined.lat[i+1], df_sql_roads_combined.lon[i+1]]))\n",
    "            \n",
    "        # insert the html popup information into folium popup\n",
    "        testa = folium.Html(\"\"\"<h3>\"\"\" + 'N1' +\"\"\"_\"\"\"+  df_sql_roads_combined.SegmentName[i] +' to ' + df_sql_roads_combined.SegmentName[i+1] +' Road'+\"\"\"\"</h3>\"\"\" , script=True)\n",
    "        popupa = folium.Popup(testa, max_width=2650)\n",
    "    \n",
    "        # create the line of the roads\n",
    "        folium.PolyLine(points, color=linear_roads.to_step(15)(df_sql_roads_combined.loc[i,'NumberOfVehicles']), \n",
    "                        weight=10,popup=popupa, opacity=0.85).add_to(my_map)\n",
    "\n",
    "    # the same as roads, but this is for bridges\n",
    "    for i in range(len(df_sql_bridges_combined)):\n",
    "\n",
    "        # blank bridges coordinates list\n",
    "        points_bridges = []\n",
    "        #insert the bridge coordinates\n",
    "        points_bridges.append(tuple([df_sql_bridges_combined.lat[i], df_sql_bridges_combined.lon[i]]))\n",
    "        \n",
    "        # insert the html popup information into folium popup        \n",
    "        testb = folium.Html(\"\"\"<h3>\"\"\" + 'N1' +\"\"\"_\"\"\"+  df_sql_bridges_combined.BridgeName[i] +' Bridge' +\"\"\"</h3>\"\"\" , script=True)\n",
    "        popupb = folium.Popup(testb, max_width=2650)\n",
    "        \n",
    "        # Layering the bridge based on its quality\n",
    "        if (df_sql_bridges_combined['Broken'][i] == 1):\n",
    "            feature_group_bridges_broken.add_child(folium.RegularPolygonMarker(points_bridges[0], popup=popupb,\n",
    "                                                    fill_color=linear_bridges.to_step(5)(5),\n",
    "                                                    number_of_sides=4, radius=7))\n",
    "\n",
    "    # Add the layer of bridges into the map            \n",
    "    my_map.add_child(feature_group_bridges_broken)\n",
    "\n",
    "    # add the check box control button into the map\n",
    "    my_map.add_child(folium.map.LayerControl())\n",
    "\n",
    "    return my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch SQL data and combine with real data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(connection,df_all_info,df_all_info_bridge,semaphore = 0):\n",
    "    \n",
    "    query_bridges = (\"SELECT* from bangladeshn1_bridges WHERE TimeStamp=\" + str(semaphore) )\n",
    "    query_roads = (\"SELECT* from bangladeshn1_roads WHERE TimeStamp=\" + str(semaphore) )\n",
    "    query_semaphore = (\"SELECT* from semaphore\")\n",
    "    query_bridgebroken = (\"SELECT* from bridgebroken\")\n",
    "\n",
    "    df_sql_bridges = pd.read_sql(query_bridges,connection)\n",
    "    df_sql_roads = pd.read_sql(query_roads,connection)\n",
    "    df_sql_semaphore = pd.read_sql(query_semaphore,connection)\n",
    "    df_sql_bridge_broken = pd.read_sql(query_bridgebroken,connection)\n",
    "\n",
    "    df_sql_roads['SegmentName'] = df_sql_roads['SegmentName'].apply(lambda x: x[:x.find('_')])\n",
    "    df_sql_bridges['BridgeName'] = df_sql_bridges['BridgeName'].apply(lambda x: x[x.find('_')+1:])\n",
    "\n",
    "    df_sql_roads_combined = pd.concat([df_sql_roads, df_all_info]).sort_values(by = 'SegmentName')\n",
    "    df_sql_roads_combined['chainage'] = df_sql_roads_combined['chainage'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_roads_combined['lat'] = df_sql_roads_combined['lat'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_roads_combined['lon'] = df_sql_roads_combined['lon'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_roads_combined['Quality'] = df_sql_roads_combined['Quality'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_roads_combined = df_sql_roads_combined.drop_duplicates(subset = ['SegmentName'], keep = 'first', inplace=False)\n",
    "    df_sql_roads_combined = df_sql_roads_combined.sort_values(by = 'chainage').fillna(method='bfill').fillna(method='ffill').reset_index(drop = True)\n",
    "\n",
    "    df_sql_bridges_combined = pd.concat([df_sql_bridges, df_all_info_bridge]).sort_values(by = 'BridgeName')\n",
    "    df_sql_bridges_combined['chainage'] = df_sql_bridges_combined['chainage'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_bridges_combined['lat'] = df_sql_bridges_combined['lat'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_bridges_combined['lon'] = df_sql_bridges_combined['lon'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_bridges_combined['Quality'] = df_sql_bridges_combined['Quality'].fillna(method='bfill').fillna(method='ffill')\n",
    "    df_sql_bridges_combined = df_sql_bridges_combined.drop_duplicates(subset = ['BridgeName'], keep = 'first', inplace=False)\n",
    "    df_sql_bridges_combined = df_sql_bridges_combined.sort_values(by = 'chainage').fillna(method='bfill').fillna(method='ffill').reset_index(drop = True)\n",
    "    \n",
    "    return df_sql_roads_combined,df_sql_bridges_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Bridge Simulation\n",
    "Please Input the desired name of the bridge to be broken in the \"Bridge_Controller.ipnyb\" while the Simio simulation and the \"Visualization.ipnyb\" running !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Sampe bridge name : N1_LRP064c,N1_LRP008a,N1_LRP187a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Please refer to Simulation_hours_all_bridges.html file for bridge name !!\n",
    "# #  Sampe bridge name : N1_LRP064c,N1_LRP008a,N1_LRP187a\n",
    "\n",
    "# print('')\n",
    "# print('      > If more than 1 Bridge, please separate the bridges name by comma!')\n",
    "# print('')\n",
    "# print('      > Please type zero or leave it blank if do not want to broke the bridge!')\n",
    "# print('')\n",
    "# print('      > Please refer to Simulation_hours_all_bridges.html file for bridge name !!')\n",
    "# print('')\n",
    "\n",
    "# list_bridges = input('(+) Please type the bridges name (Case Sensitive): ')\n",
    "# print('')\n",
    "\n",
    "# try :\n",
    "#     list_bridges = list_bridges.split(',')\n",
    "#     for bridge in list_bridges:\n",
    "#         try:\n",
    "#             query_broken = (\"UPDATE epa1351group5.bridgebroken SET Broken = 1 WHERE BridgeName = \" +\"\"\"'\"\"\"+bridge+\"\"\"'\"\"\")\n",
    "\n",
    "#             connection = pymysql.connect(host='localhost', user='epa1351user', passwd='xgt65RR##', db='epa1351group5')\n",
    "#             curs = connection.cursor()\n",
    "\n",
    "#             curs.execute(query_broken)\n",
    "\n",
    "#         except:\n",
    "#             print('No Bridge Name ',bridge,' in the database!')\n",
    "\n",
    "# except:\n",
    "#     if list_bridges == '0' or list_bridges == '' :\n",
    "#         print('(!) No Bridge will be broke down in simulation !')\n",
    "#         print('')\n",
    "        \n",
    "#     else:\n",
    "#         print('(x) Please input precise bridge name or check database connection!!')\n",
    "#         print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time visualization for every hour in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please get the simulation running before you run these 2 cell of code below !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    delay=0.0005\n",
    "\n",
    "    # set semaphore query\n",
    "    query_semaphore_check = (\"SELECT semaphore from semaphore\")\n",
    "\n",
    "    # set simulation timer and counter to zero\n",
    "    counter = 0\n",
    "    simTime = 0\n",
    "\n",
    "    connection = pymysql.connect(host='localhost', user='epa1351user', passwd='xgt65RR##', db='epa1351group5')\n",
    "    new_roads, new_bridges = fetch_data(connection, df_all_info, df_all_info_bridge)  \n",
    "   \n",
    "    fn='Simulation_hours_'\n",
    "\n",
    "    mymap1b = plot_map_mini(new_bridges,new_roads)\n",
    "    # Save the map into html format called results that saved in the working directory\n",
    "    mymap1b.save(fn+'0.html')\n",
    "    webbrowser.open(fn+'0.html')\n",
    "\n",
    "    tmpurl='file://{path}/{mapfile}'.format(path=os.getcwd(),mapfile=(fn+'.html'))\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(tmpurl)\n",
    "    #Give the map tiles some time to load\n",
    "    time.sleep(delay)\n",
    "    browser.save_screenshot(fn+'.png')\n",
    "    browser.quit()\n",
    "    \n",
    "    starting_point = 1\n",
    "    # Endless While loop untill no new simulation values are found by checking 10 times\n",
    "    while counter<10:\n",
    "\n",
    "        # check if semaphore has changed\n",
    "        connection = pymysql.connect(host='localhost', user='epa1351user', passwd='xgt65RR##', db='epa1351group5')\n",
    "        query_semaphore_check_df = pd.read_sql(query_semaphore_check,connection)\n",
    "        newSimTime = query_semaphore_check_df.index[-1]\n",
    "\n",
    "        if newSimTime > simTime: # there is new simulation data available\n",
    "            start_time = timeit.default_timer()\n",
    "            \n",
    "            simTime = newSimTime\n",
    "            counter = 0\n",
    "            \n",
    "            # get new simulation data        \n",
    "            new_roads, new_bridges = fetch_data(connection, df_all_info, df_all_info_bridge, starting_point)  \n",
    "\n",
    "            #plot on the map\n",
    "            mymap2 = plot_map_mini(new_bridges,new_roads)\n",
    "\n",
    "            fn='Simulation_hours_'+str(starting_point)\n",
    "            # Save the map into html format called results that saved in the working directory\n",
    "            mymap2.save(fn+'.html') \n",
    "            # Open new tab automatically for the html output that produced\n",
    "            webbrowser.open(fn+'.html')\n",
    "\n",
    "            tmpurl='file://{path}/{mapfile}'.format(path=os.getcwd(),mapfile=(fn+'.html'))\n",
    "            browser = webdriver.Chrome()\n",
    "            browser.get(tmpurl)\n",
    "            #Give the map tiles some time to load\n",
    "            time.sleep(delay)\n",
    "            browser.save_screenshot(fn+'.png')\n",
    "            browser.quit()\n",
    "            \n",
    "            starting_point = starting_point+1\n",
    "            \n",
    "            stop_time = timeit.default_timer()\n",
    "\n",
    "            print('Total time for mapping simulation hour ',starting_point,' was ', (stop_time-start_time), 'Seconds')\n",
    "\n",
    "        else: # wait 8 seconds to try again\n",
    "            counter = counter + 1\n",
    "            time.sleep(10)\n",
    "\n",
    "    print('No new data avaliable (Simulation Done!) or Please check the simulation or database connection!')\n",
    "    \n",
    "    png_dir = \".\"\n",
    "    images = []\n",
    "    for subdir, dirs, files in os.walk(png_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file_path.endswith(\".png\"):\n",
    "                images.append(imageio.imread(file_path))\n",
    "    imageio.mimsave('Hourly_Gif.gif', images,fps=1)\n",
    "    \n",
    "except:\n",
    "    \n",
    "    png_dir = \".\"\n",
    "    images = []\n",
    "    for subdir, dirs, files in os.walk(png_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file_path.endswith(\".png\"):\n",
    "                images.append(imageio.imread(file_path))\n",
    "    imageio.mimsave('Hourly_Gif.gif', images,fps=1)\n",
    "    \n",
    "    print('Database or simulation has been reset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_dir = \".\"\n",
    "images = []\n",
    "for subdir, dirs, files in os.walk(png_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        if file_path.endswith(\".png\"):\n",
    "            images.append(imageio.imread(file_path))\n",
    "imageio.mimsave('Hourly_Gif.gif', images,fps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for every hour change recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animatedGif = \"Hourly_Gif.gif\" #path relative to your notebook\n",
    "\n",
    "file = open(animatedGif , \"rb\")\n",
    "image = file.read()\n",
    "progress= Image(\n",
    "    value=image,\n",
    "    format='gif',\n",
    "    width=600,\n",
    "    height=400)\n",
    "\n",
    "play = widgets.Play(\n",
    "    #interval=100,\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=24,\n",
    "    step=1,\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "slider = widgets.IntSlider()\n",
    "widgets.jslink((play, 'value'), (slider, 'value'))\n",
    "VBox([HBox([play, slider]),progress])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
